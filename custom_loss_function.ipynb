{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tensorflow.keras.optimizers import *\n",
    "import glob\n",
    "import time\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.strftime(\"%Y_%m_%d_%H_%M\", time.localtime())\n",
    "\n",
    "def scheduler(epoch):\n",
    "  if epoch < 6:\n",
    "    return 0.0001\n",
    "  else:\n",
    "    return 0.0001 * tf.math.exp(0.1 * (10 - epoch))\n",
    "\n",
    "def ref_only_loss(y_true, y_pred, thresh):\n",
    "    mask = tf.math.greater(y_true, thresh)\n",
    "    y_true2 = tf.boolean_mask(y_true, mask)\n",
    "    y_pred2 = tf.boolean_mask(y_pred, mask)\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    huber = tf.keras.losses.Huber()\n",
    "    return mse(y_true2, y_pred2)\n",
    "\n",
    "def refl_loss(thresh):\n",
    "    def ref(y_true, y_pred):\n",
    "        return ref_only_loss(y_true, y_pred, thresh)\n",
    "    return ref\n",
    "\n",
    "#\n",
    "# Mean Absolute Error metric\n",
    "#\n",
    "def mae(y_true, y_pred):\n",
    "            \n",
    "    eval = K.abs(y_pred - y_true)\n",
    "    eval = K.mean(eval, axis=-1)\n",
    "        \n",
    "    return eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# set up the run information\n",
    "############################\n",
    "output_root_directory = '/glade/work/hardt/models'\n",
    "model_run_name        = 'unet_v1p0'\n",
    "from unet_model_v1p0 import unet\n",
    "#--------------------------\n",
    "output_model_name     = 'trained_model_{}.h5'\n",
    "log_dir = os.path.join(output_root_directory, model_run_name, 'logs', 'fit',output_model_name.format(t))\n",
    "feature_data     = '/glade/work/hardt/ds612/2000-2013_June-Sept_scale_REFL.nc'\n",
    "label_data       = '/glade/work/hardt/ds612/2000-2013_June-Sept_scale_maxW.nc'\n",
    "#feature_data     = '/glade/work/hardt/ds612/2000-2013_June-Sept_CTRLradrefl_REFL.nc'\n",
    "#label_data       = '/glade/work/hardt/ds612/2000-2013_June-Sept_CTRL3D_maxW.nc'\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(output_root_directory, model_run_name)\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# load the data\n",
    "#\n",
    "fds = xr.open_dataset(feature_data)\n",
    "lds = xr.open_dataset(label_data)\n",
    "feature = fds.refl.values\n",
    "label = lds.maxW.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# set up the the data sets\n",
    "#\n",
    "#feature_dataset = tf.data.Dataset.from_tensor_slices(feature[0:6112,:,:,np.newaxis])\n",
    "#label_dataset = tf.data.Dataset.from_tensor_slices(label[0:6112,:,:,np.newaxis])\n",
    "#train_dataset = tf.data.Dataset.zip((feature_dataset, label_dataset))\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((feature[0:6112,:,:,np.newaxis], label[0:6112,:,:,np.newaxis]))\n",
    "val_dataset   = tf.data.Dataset.from_tensor_slices((feature[6113:7649,:,:,np.newaxis], label[6113:7649,:,:,np.newaxis]))\n",
    "print(train_dataset)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 6112\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE, reshuffle_each_iteration=True).batch(BATCH_SIZE, drop_remainder=True)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# set up the model\n",
    "#\n",
    "output_model = os.path.join(output_path, output_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet()\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "#model.compile(optimizer = SGD(lr=1e-4, momentum=0.5), loss=refl_loss(thresh=0.5), metrics = ['accuracy'], run_eagerly=True)\n",
    "model.compile(optimizer = SGD(lr=1e-4, momentum=0.5), loss=refl_loss(0.01), metrics = ['mae'], run_eagerly=True)\n",
    "#model.compile(optimizer = SGD(lr=1e-4, momentum=0.5), loss=mse, metrics = ['accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# callbacks\n",
    "#\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model_save_callback = tf.keras.callbacks.ModelCheckpoint(filepath='/glade/scratch/hardt/unet_v1/trained_model_{epoch}.h5',save_freq='epoch')\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(output_path,\"weights_best.h5\"), monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
    "LRS = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=50, validation_data=val_dataset, callbacks=[LRS, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# write out the trained model\n",
    "#\n",
    "t = time.strftime(\"%Y_%m_%d_%H_%M\", time.localtime())\n",
    "model.save(output_model.format(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
