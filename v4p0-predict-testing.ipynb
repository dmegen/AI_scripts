{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# set up the run information\n",
    "############################\n",
    "root_directory   = '/glade/work/hardt/models'\n",
    "\n",
    "model_run_name   = 'unet_v4p0'\n",
    "model            = 'trained_model_feature-0to6.5km_at_500m_steps_label-3000m_2020_09_30_05_29.h5'\n",
    "                    \n",
    "output_data_name = 'predict_' + model + '.nc'\n",
    "\n",
    "feature_data     = '/glade/work/hardt/ds612/2000-2013_June-Sept_QRAIN_INTERP_AGL_0to7km_at_500m_steps.nc'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "data_fraction_for_test = 0.10\n",
    "\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run_dir = os.path.join(root_directory, model_run_name)\n",
    "output_data = os.path.join(model_run_dir, output_data_name)\n",
    "input_model = os.path.join(model_run_dir, model)\n",
    "\n",
    "if not os.path.isfile(input_model):\n",
    "    print(\"ERROR: Missing input model file\", input_model)\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of images: 9568\n",
      "Test data start image: 8640\n",
      "Test data end image: 9568\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# set up the test data set\n",
    "#\n",
    "fds = xr.open_dataset(feature_data)\n",
    "feature = fds.QRAIN.values\n",
    "\n",
    "num_images = feature.shape[0]\n",
    "\n",
    "test_data_start = int(num_images * (1 - data_fraction_for_test))\n",
    "test_data_start = (num_images - int((num_images - test_data_start) / BATCH_SIZE) * BATCH_SIZE) \n",
    "test_data_end = num_images\n",
    "\n",
    "print ()\n",
    "print (\"Number of images:\", num_images)\n",
    "print (\"Test data start image:\", test_data_start)\n",
    "print (\"Test data end image:\", test_data_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9568, 15, 256, 256)\n",
      "(9568, 256, 256, 15)\n"
     ]
    }
   ],
   "source": [
    "print(feature.shape)\n",
    "feature = np.moveaxis(feature, 1, 3)\n",
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((feature[test_data_start:test_data_end,:,:,:14]))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (32, 256, 256, 14), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
